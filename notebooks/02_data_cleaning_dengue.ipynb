{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ecf32e7-c152-4579-94c2-48f8e577375a",
   "metadata": {},
   "source": [
    "# Data Cleaning Notebook for Dengue Transfer Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5b9dc-b801-4e0e-8009-3f1f96aa4995",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Conduct EDA for TensorFlow transfer learning pipeline to forecast **weekly dengue cases** (`total_cases`) from 22 multivariate weather/environmental features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc88d993-c3b1-4a6c-af85-a4d74a00bb26",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Dengue ML datasets track environmental and temporal factors influencing Aedes mosquito breeding and virus transmission in tropical regions like San Juan and Iquitos.\n",
    "\n",
    "- #### Temporal Features\n",
    "    - **city**: Location identifier (e.g., 'sj' for San Juan, 'iq' for Iquitos)—captures city-specific mosquito/dengue patterns.\n",
    "    - **year, weekofyear, week_start_date**: Time granularity for seasonality; dengue peaks during rainy seasons (weekofyear critical for lagged effects).\n",
    "\n",
    "- #### Vegetation Indices (NDVI)\n",
    "    - **ndvi_ne, ndvi_nw, ndvi_se, ndvi_sw**: Normalized Difference Vegetation Index by city quadrant. Higher NDVI indicates lush vegetation providing mosquito shade/breeding sites; key for Aedes habitat detection via satellite.\n",
    "\n",
    "- #### Precipitation \\& Water\n",
    "    - **precipitation_amt_mm**: Rainfall amount—creates standing water breeding sites.\n",
    "    - **reanalysis_precip_amt_kg_per_m2, reanalysis_sat_precip_amt_mm**: Reanalysis (modeled) precipitation variants confirming observed rain.\n",
    "    - **station_precip_mm**: Ground station measurements—most direct rain proxy.\n",
    "\n",
    "- #### Temperature Metrics\n",
    "    - **reanalysis_air_temp_k, reanalysis_avg_temp_k, reanalysis_max_air_temp_k, reanalysis_min_air_temp_k**: Reanalysis temps in Kelvin; optimal Aedes range 26-32°C accelerates larval development/virus replication.\n",
    "    - **station_avg_temp_c, station_max_temp_c, station_min_temp_c**: Station temps in Celsius—ground truth validation.\n",
    "    - **station_diur_temp_rng_c**: Diurnal range; wider swings stress mosquitoes.\n",
    "    - **reanalysis_tdtr_k**: Temperature diurnal temperature range (reanalysis).\n",
    "\n",
    "- #### Humidity \\& Moisture\n",
    "    - **reanalysis_dew_point_temp_k**: Dew point—direct humidity proxy; high values (>20°C) favor mosquito survival.\n",
    "    - **reanalysis_relative_humidity_percent**: Relative humidity %—critical for egg/larval viability.\n",
    "    - **reanalysis_specific_humidity_g_per_kg**: Absolute moisture content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf887f4-3caa-4743-92fb-64e063d6df4c",
   "metadata": {},
   "source": [
    "### Notebook sections for the second project notebook (Data Cleaning)\n",
    "1. Get Data\n",
    "2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e08f0ea-ff58-4fe2-b0f1-066eea4b4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Any, Dict, Union\n",
    "import gc\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set one level up as project root|\n",
    "if os.path.abspath(\"..\") not in sys.path:\n",
    "    sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "    \n",
    "from src.config import ProjectConfig  # project config file parser\n",
    "from src.utils.eda import value_streaks, top_correlations\n",
    "from src.utils.visualizations import compute_correlations_matrix, \\\n",
    "                display_distributions, random_color, random_colormap, \\\n",
    "                display_timeseries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "from src.utils.eda import top_correlations, top_vif\n",
    "from src.utils.utils import _check_feature_presence, load_file, save_file\n",
    "from src.preprocessing.clean import cap_outliers, drop_nan_rows, \\\n",
    "                                    median_groupwise_impute, pipe_clean\n",
    "from src.preprocessing.engineer import reduce_features, remove_features\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "# from matplotlib.axis import Axis\n",
    "# from matplotlib.dates import MonthLocator, YearLocator, DateFormatter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24bdf12c-01f6-4f80-87d9-45ac974899f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnfg = ProjectConfig.load_configuration()\n",
    "PATH_TO_RAW_DATA = cnfg.data.dirs[\"raw\"]\n",
    "FILE_TRAIN_RAW= cnfg.data.files[\"features_train\"]\n",
    "FILE_TEST_RAW = cnfg.data.files[\"features_test\"]\n",
    "FILE_LABELS_RAW = cnfg.data.files[\"labels_train\"]\n",
    "\n",
    "PATH_TO_INTERMEDIATE_DATA = cnfg.data.dirs[\"intermediate\"]\n",
    "FILE_NAN_CLEAN = cnfg.data.files[\"nan_mask\"]\n",
    "FILE_TRAIN_CLEAN = cnfg.data.files[\"features_clean\"]\n",
    "FILE_LABELS_CLEAN = cnfg.data.files[\"labels_clean\"]\n",
    "\n",
    "TARGET = cnfg.preprocess.feature_groups[\"target\"]\n",
    "ENV_FEAT_PREFIX = cnfg.preprocess.feature_groups[\"env_prefixes\"]\n",
    "CITYGROUP_FEAT = cnfg.preprocess.feature_groups[\"city\"]\n",
    "WEEK_FEAT = cnfg.preprocess.feature_groups[\"week\"]\n",
    "DATETIME_FEAT = cnfg.preprocess.feature_groups[\"datetime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253393b7-1fff-4956-81d9-63ec1aef02cf",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247bd520-f0df-40cc-8b78-8361d8b391db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib.PosixPath"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(FILE_TRAIN_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd2c7d3-1a82-4f2d-a83e-e0ca57449f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = load_file(path=PATH_TO_RAW_DATA / FILE_TRAIN_RAW, datetime_col=DATETIME_FEAT)\n",
    "df_test_raw = load_file(path=PATH_TO_RAW_DATA / FILE_TEST_RAW, datetime_col=DATETIME_FEAT)\n",
    "df_labels_raw = load_file(path=PATH_TO_RAW_DATA / FILE_LABELS_RAW)\n",
    "list_raw_df = [df_train_raw, df_test_raw, df_labels_raw]\n",
    "env_features = [f for f in df_train_raw if f.startswith(tuple(ENV_FEAT_PREFIX))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2344f95e-bc70-4629-b9bb-5dee227b7cc9",
   "metadata": {},
   "source": [
    "***To reduce data snooping, slice last entries for both dataset cities***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8037cfa4-6661-4b33-85c1-67b00f83966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_pct = 0.05\n",
    "cities_first_i = df_train_raw.groupby(by=CITYGROUP_FEAT)[\"week_start_date\"].idxmin()  # Series w Start indices\n",
    "cities_last_i = df_train_raw.groupby(by=CITYGROUP_FEAT)[\"week_start_date\"].idxmax()  # Series w end indices\n",
    "cities_last_i = (cities_last_i - (cities_last_i - cities_first_i) * holdout_pct).astype(int)  # indice math with Series\n",
    "period = tuple(slice(cities_first_i[city], cities_last_i[city], 1) for city in cities_last_i.index[::-1])  # Create tuple of slices from 2 Series\n",
    "df_train_raw_eda = df_train_raw.iloc[np.r_[period]].reset_index(drop=True)  # apply defuned slices\n",
    "df_labels_raw_eda = df_labels_raw.iloc[np.r_[period]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393e6e2-6dfe-4e9c-b4aa-df94046298a1",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11f6de-d321-4b11-af46-5a800bad6442",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- [x] Cap BEFORE median computation (Winsorization - cap extreme values at specified threshold):\n",
    "    - 1%/99% threshold for both models\n",
    "    - do not cap targets\n",
    "- [X] Remove rows with over 50% of NaN\n",
    "- [X] Impute NaNs with the groupwise median.\n",
    "- [ ] (OPTIONAL, if outliers still there) Reapply outlier handling AFTER imputation with 5%/95% threshold:\n",
    "    - larger threshold preserves more of original distribution shape than tail-focussed 1%/99% threshold\n",
    "    - should not cap much of the data at this stage (CHECK FOR AFFECTED DATAPOINT COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b700b1-baf8-44e0-89f5-d1b4529c1f63",
   "metadata": {},
   "source": [
    "### Outlier handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f86e3008-9fa9-4c66-8e5f-d35d3cf61dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove after cleaning\n",
    "\n",
    "# def cap_outliers(data: pd.DataFrame, features: List[str]=None,\n",
    "#                  group_keys: List[str]=None,\n",
    "#                  lower_cap:float=None, upper_cap:float=None,\n",
    "#                 output_stats:bool=True) -> Dict[str, Any]:\n",
    "#     \"\"\"\n",
    "#     Perform groupwise Winsorization (percentile clipping) on specified features to handle outliers.\n",
    "#     Automatically filter environmental features from config prefixes if not specified.\n",
    "#     :param data: Input pandas DataFrame.\n",
    "#     :param features: List of column names to clip. Default None auto-selects env features \n",
    "#            from prefixes defined in config.yaml.\n",
    "#     :param group_keys: List of columns to group by for quantile calculation. Default None uses \n",
    "#            config.yaml 'city' grouping.\n",
    "#     :param lower_cap: Lower percentile for clipping (0-1). Default None uses config.yaml \n",
    "#            'outlier_perc.lower' (originally 0.01).\n",
    "#     :param upper_cap: Upper percentile for clipping (0-1). Default None uses config.yaml \n",
    "#            'outlier_perc.upper' (originally 0.99).\n",
    "#     :param output_stats: If True, returns % rows changed per feature. Default True.\n",
    "#     :return: Dict containing:\n",
    "#            - 'data': Clipped DataFrame copy (original unchanged)\n",
    "#            - 'capped_row_prc': Series of % rows clipped per feature (if output_stats=True)\n",
    "#     \"\"\"\n",
    "#     if features is None:\n",
    "#         features = [f for f in data.columns if f.startswith(\n",
    "#             tuple(cnfg.preprocess.feature_groups[\"env_prefixes\"]))]\n",
    "#     if group_keys is None:\n",
    "#         group_keys = cnfg.preprocess.feature_groups[\"city\"]\n",
    "#     if lower_cap is None:\n",
    "#         lower_cap = cnfg.preprocess.outlier_perc[\"lower\"]\n",
    "#     if upper_cap is None:\n",
    "#         upper_cap = cnfg.preprocess.outlier_perc[\"upper\"]\n",
    "\n",
    "#     data_no_outliers = data.copy()\n",
    "#     data_no_outliers[features] = data_no_outliers.groupby(by=group_keys)[features].transform(\n",
    "#         lambda group: group.clip(\n",
    "#             lower=group.quantile(lower_cap), upper=group.quantile(upper_cap)))\n",
    "\n",
    "#     if output_stats:\n",
    "#         capped_row_percent = round(\n",
    "#             ((data[features] != data_no_outliers[features]).sum() / len(data) * 100), 2)\n",
    "#         return {\"data\": data_no_outliers,\n",
    "#                 \"capped_row_prc\": capped_row_percent}\n",
    "#     return {\"data\": data_no_outliers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837af435-94c0-40fb-a6d0-be77b78359a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output = cap_outliers(data=df_train_raw)\n",
    "df_train_clean = intermediate_output[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc17e70-e243-4a51-a8d4-8dba1c5c5034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ndvi_ne                                  15.25\n",
       "ndvi_nw                                   5.63\n",
       "ndvi_se                                   3.71\n",
       "ndvi_sw                                   3.71\n",
       "precipitation_amt_mm                      2.40\n",
       "reanalysis_air_temp_k                     2.82\n",
       "reanalysis_avg_temp_k                     2.82\n",
       "reanalysis_dew_point_temp_k               2.88\n",
       "reanalysis_max_air_temp_k                 2.68\n",
       "reanalysis_min_air_temp_k                 2.61\n",
       "reanalysis_precip_amt_kg_per_m2           2.88\n",
       "reanalysis_relative_humidity_percent      2.88\n",
       "reanalysis_sat_precip_amt_mm              2.40\n",
       "reanalysis_specific_humidity_g_per_kg     2.88\n",
       "reanalysis_tdtr_k                         2.82\n",
       "station_avg_temp_c                        5.01\n",
       "station_diur_temp_rng_c                   5.01\n",
       "station_max_temp_c                        3.09\n",
       "station_min_temp_c                        2.68\n",
       "station_precip_mm                         2.61\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output[\"capped_row_prc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019674b2-b5a6-4cb7-9d58-253b0e34f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment cell for visual check on new distributions for selected features after outlier cliping/Winsorization \n",
    "\n",
    "# selected_distro_EDA_features = [\"ndvi_ne\", \"precipitation_amt_mm\", \"station_diur_temp_rng_c\", \"station_max_temp_c\",\n",
    "#        \"station_min_temp_c\", \"station_precip_mm\"]\n",
    "# # selected_distro_EDA_features = [feature for feature in df_train_raw_eda.select_dtypes(\"float\") if not feature.startswith(\"reanalysis\")]  # used for outlier check\n",
    "\n",
    "# for numeric_feature in selected_distro_EDA_features:\n",
    "#     display_distributions(data=df_train_clean[selected_distro_EDA_features],\n",
    "#                           features=[numeric_feature],\n",
    "#                           title_prefix=numeric_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a1a43-b25f-4fc7-8379-f25914e39eb1",
   "metadata": {},
   "source": [
    "**Conclusion**:\n",
    "- Extreme outliers are removed\n",
    "- Data ranges and variations seam to be credible for tropical climate\n",
    "- No need to adjust 1%/99% clipping percentailes or conduct second round of cliping/Winsorization\n",
    "- Adjusted row percentaga is rasonable from ~2-15% (does not exceed 20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e32471-0069-4400-813b-343aecb9cbdb",
   "metadata": {},
   "source": [
    "### NaN handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c12bf6-5151-4b0c-86f4-f8b6057fd628",
   "metadata": {},
   "source": [
    "- Remove rows with > 50% NaN values:\n",
    "    - also removes all rowws for `wekofyear` # 53 that do not have observational or analytical data (a likely data collection bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc434c90-b490-48bd-a015-06907a312971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove after cleaning\n",
    "\n",
    "# def drop_nan_rows(X: pd.DataFrame, y: pd.Series | None = None,\n",
    "#                   threshold_percent: float = 0.5):\n",
    "#     \"\"\"\n",
    "#     Drop rows with NaN values exceeding threshold_percent of columns.\n",
    "    \n",
    "#     :param X: pandas DataFrame of features.\n",
    "#     :param y: Optional target array/series. Default None.\n",
    "#     :param threshold_percent: Min non-null fraction required [0,1]. Default 0.5.\n",
    "#     :return: Filtered X (and y if provided), both with reset_index().\n",
    "#     \"\"\"\n",
    "#     row_drop_threshold = int(len(X.columns) * threshold_percent)\n",
    "#     result = X.dropna(thresh=row_drop_threshold)\n",
    "#     if y is not None:\n",
    "#         return result.reset_index(), y.iloc[result.index].reset_index()\n",
    "#     return result.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa9f582-1dfe-4715-a41e-b378fd7fb1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean, df_labels_clean = drop_nan_rows(X=df_train_clean, y=df_labels_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc9c3b34-34e6-4082-84bb-a95bd6b483d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove after cleaning\n",
    "\n",
    "# def median_groupwise_impute(X: pd.DataFrame,\n",
    "#                             group_keys: List[str] = ['city', 'weekofyear']):\n",
    "#     \"\"\"\n",
    "#     Impute NaN values in numeric columns using median within specified group keys.\n",
    "    \n",
    "#     :param X: pandas DataFrame containing grouping columns and features to impute.\n",
    "#     :param group_keys: List of column names for grouping. Default ['city', 'weekofyear'].\n",
    "#     :return: Copy of input DataFrame with NaNs filled by group-wise medians.\n",
    "#     \"\"\"\n",
    "#     missing_keys = set(group_keys) - set(X.columns)\n",
    "#     if missing_keys:\n",
    "#         raise ValueError(f\"Missing group keys {missing_keys}\")\n",
    "\n",
    "#     X_no_nan = X.copy()\n",
    "#     cols_with_nan = X_no_nan.select_dtypes(include=\"number\")\\\n",
    "#         .columns[X_no_nan.select_dtypes(include=\"number\").isna().sum() > 0].to_list()\n",
    "\n",
    "#     if len(cols_with_nan) > 0:\n",
    "#         X_no_nan[cols_with_nan] = X_no_nan[cols_with_nan + group_keys]\\\n",
    "#             .groupby(by=group_keys)[cols_with_nan]\\\n",
    "#             .transform(lambda group: group.fillna(group.median()))\n",
    "#     return X_no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "276c1f80-f824-4d1a-a7c6-3224c9aca0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean, df_nan_mask = median_groupwise_impute(X=df_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcd76c48-17ac-48dc-abcd-c3b2a4031960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'year', 'weekofyear', 'total_cases'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "329264c2-7b23-4561-999e-99c1a212b936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any NaNs left\n",
    "df_train_clean.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccc39a39-8377-4986-864b-c91531dd65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove after cleaning\n",
    "\n",
    "# plt.figure(figsize=(18, 6))  # df_train_raw.shape[1]\n",
    "# sns.heatmap(\n",
    "#     # median_groupwise_impute(df_train_clean).isna(),\n",
    "#     df_train_clean.isna(),\n",
    "#     cmap='plasma', cbar=False)\n",
    "# plt.title(\"Post-clean NaN location check.\\n\", \n",
    "#           fontsize=13, fontweight=\"bold\")\n",
    "# plt.xticks(rotation=45, ha='right', rotation_mode='anchor')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f3029-12cd-4204-8b7b-e7d1d69f8727",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- primary imputation method: median of all other weekly data from subset of same city data:\n",
    "    - median because data has outliers\n",
    "    - data misigness is acceptable - even in worst cases (after removing week 53 that has no data) thera are more than 50% and at least 6 data pints available to produce `city`+`weekofyear` medians (see EDA table).\n",
    "    - Features in the datset have strong seasonality (rain, temperature, humidity, NDVI). Same week median can handle this.\n",
    "    - moderately well handles different issues with the dataset - scattered NaNs, long streaks (entire season of 15-weeks for `NDVI`)\n",
    "    - simple to implement\n",
    "- Other imputation methods considered:\n",
    "    - Data reconstruction (eg station average or range features from station_max and station_min):\n",
    "        - discarded as performing same calculations on non-nan data show significant discrepancies between calculated and original data\n",
    "    - horizontal imputation from potentially related Reanalysis data:\n",
    "        - discarded: top correlations for station mesurement and reanalysis data do differ accross city data subsets. San Juan has more promissing correlation ranges from ~0.5 (`station_precip_mm`) to ~0.88 (`station_avg_temp_c`) while Iquitos respective ranges are from below 0.4 (`station_precip_mm`) to ~0.6 (`station_avg_temp_c`). Considering that almost all of the missing data for station measurements are in Iquitos, the correlations do not explain enough variance (R^2) and thus median imputation is potentially better tool.\n",
    "    - Temporal interpolation (np.interp, splines):\n",
    "        -  discarded: destroys temporal patterns for long NaN streaks (eg line pattern for entire season or month)\n",
    "    -  KNN/multi-feature models:\n",
    "        - discarded: Complexity vs expected gains. Too much effort and bug risk versus potentially minimal model improvements when simple median imputation used.  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a51c3-df65-46e8-be29-98670b55c572",
   "metadata": {},
   "source": [
    "<!-- ### Remove selected multicolinear features\n",
    "- [X] Remove initial `config.yaml` milticolinear features form dataframe\n",
    "- [X] Assess city-wise VIF to EDA instead of correlation matrix for one-vs-all relationships.\n",
    "- [ ] Remove features with VIF > 10\n",
    "- [X] always prefer station_* over reanalysis_* -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7cd16-dff0-4dbb-86b5-321d1b21a6f2",
   "metadata": {},
   "source": [
    "### Cleaning pipeline\n",
    "- [X] run cleaning steps in sequence\n",
    "- [X] save clean data and nan mask to the disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dff91bf9-9df3-4a17-a87e-5ed4210ab962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - remove after cleanimng\n",
    "\n",
    "# def save_file(df: pd.DataFrame, path: Union[str, Path], overwrite=False):\n",
    "#     \"\"\"\n",
    "#     Save pandas DataFrame to CSV or Parquet file with automatic directory creation \n",
    "#     and timestamped to avoid overwrites.\n",
    "#     :param df: DataFrame to save.\n",
    "#     :param path: File path as string or Path object (.csv, .parquet, or .pqt).\n",
    "#     :param overwrite: If True, overwrite existing file. If False (default), \n",
    "#                       create timestamped version like `file_20260201_1947.csv`.\n",
    "#     :return: Final Path object where file was saved.\n",
    "#     :raises ValueError: If DataFrame is empty or file format unsupported.\n",
    "#     \"\"\"\n",
    "#     path=Path(path)\n",
    "#     if df.empty:\n",
    "#         raise ValueError(\"Attemting to save empty DataFrame\")\n",
    "#     if not path.parent.is_dir():\n",
    "#         logging.info(\"No directory for provided path. Creating one.\")\n",
    "#         path.parent.mkdir(parents=True)\n",
    "#     if path.is_file():\n",
    "#         if overwrite:\n",
    "#             logging.info(\"Path file present, overwriting.\")\n",
    "#         else:\n",
    "#             timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "#             path = path.with_stem(f\"{path.stem}_{timestamp}\")\n",
    "#             logging.info(f\"Path file present, creating new one: {path.name}.\")\n",
    "            \n",
    "#     if path.suffix.lower() == \".csv\":\n",
    "#         df.to_csv(path, index=False)\n",
    "#     elif path.suffix.lower() in [\".parquet\", \".pqt\"]:\n",
    "#         df.to_parquet(path, index=False, engine='fastparquet')\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unsupported file format: {path.suffix}\")\n",
    "#     logging.info(f\"Saved {df.shape} shaped data to {path}\")\n",
    "#     return path\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7afbf36e-cfed-4301-a03d-b1a797c05e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Path file present, creating new one: dengue_nan_mask_20260202_1412.parquet.\n",
      "INFO:root:Saved (1446, 11) shaped data as dengue_nan_mask_20260202_1412.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/butros/Documents/kursi/pasmaciba/PashPrjekts/finetune2025/dengue-transfer-learn/data/intermediate/dengue_nan_mask_20260202_1412.parquet')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_file(df=df_nan_mask, path=PATH_TO_INTERMEDIATE_DATA / FILE_NAN_CLEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f222b5fd-999b-40a5-875f-bdae8bf9dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO - remove after cleanimng\n",
    "\n",
    "# def pipe_clean(manual_dirs: Dict[str, Path] | None=None,\n",
    "#                manual_files: Dict[str, Path] | None=None,\n",
    "#                datetime_col: str=None,\n",
    "#                overwrite_files: bool=False) -> Dict[str, Any]:\n",
    "#     \"\"\"\n",
    "#     Data cleaning pipeline for features and targets.\n",
    "#     Handle outlier capping, NaN row dropping, and groupwise median imputation in sequence.\n",
    "#     :param manual_dirs: Dict of directory paths to override config.yaml dirs. \n",
    "#         Keys: 'raw', 'intermediate'. Default None uses config.yaml data.dirs.\n",
    "#     :param manual_files: Dict of filenames to override config.yaml files. \n",
    "#         Keys: 'features_train', 'labels_train', 'features_clean', 'labels_clean', 'nan_mask'. \n",
    "#         Default None uses config.yaml data.files.\n",
    "#     :param datetime_col: Name of datetime column for parsing. Default None uses\n",
    "#                             config.yaml preprocess.feature_groups[\"datetime\"].\n",
    "#     :param overwrite_files: If True, overwrites existing saved files. Default False.\n",
    "    \n",
    "#     :return: Dict containing:\n",
    "#         - 'X_clean_save_path': Path where cleaned features saved\n",
    "#         - 'X_clean_data': Cleaned features DataFrame\n",
    "#         - 'X_capped_rows_prc': Float % of rows affected by outlier capping\n",
    "#         - 'y_clean_save_path': Path where cleaned targets saved  \n",
    "#         - 'y_clean_data': Cleaned targets DataFrame\n",
    "#         - 'nan_mask_save_path': Path where NaN mask saved\n",
    "#         - 'nan_mask_data': DataFrame tracking imputed locations (for feature engineering)\n",
    "#     \"\"\"\n",
    "#     dirs = cnfg.data.dirs\n",
    "#     filenames = cnfg.data.files\n",
    "#     if manual_dirs is not None:\n",
    "#         dirs = manual_dirs\n",
    "#     if manual_files is not None:\n",
    "#         filenames = manual_files\n",
    "\n",
    "#     X_clean = load_file(path=dirs[\"raw\"] / filenames[\"features_train\"],\n",
    "#                         datetime_col=datetime_col)\n",
    "#     y_clean = load_file(path=dirs[\"raw\"] / filenames[\"labels_train\"],\n",
    "#                         datetime_col=datetime_col)\n",
    "    \n",
    "#     caping_output = cap_outliers(data=X_clean)\n",
    "#     X_clean = caping_output[\"data\"]\n",
    "#     X_clean, y_clean = drop_nan_rows(X=X_clean, y=y_clean)\n",
    "#     X_clean, df_nan_mask = median_groupwise_impute(X=X_clean)\n",
    "\n",
    "#     X_save_path = save_file(df=X_clean, path=dirs[\"intermediate\"] / filenames[\"features_clean\"],\n",
    "#                             overwrite=overwrite_files)\n",
    "#     y_save_path = save_file(df=y_clean, path=dirs[\"intermediate\"] / filenames[\"labels_clean\"],\n",
    "#                             overwrite=overwrite_files)\n",
    "#     nan_mask_save_path = save_file(df=df_nan_mask, path=dirs[\"intermediate\"] / filenames[\"nan_mask\"],\n",
    "#                                    overwrite=overwrite_files)\n",
    "    \n",
    "#     return {\"X_clean_save_path\": X_save_path,\n",
    "#             \"X_clean_data\": X_clean,\n",
    "#             \"X_capped_rows_prc\": caping_output[\"capped_row_prc\"],\n",
    "#             \"y_clean_save_path\": y_save_path,\n",
    "#             \"y_clean_data\": y_clean,\n",
    "#             \"nan_mask_save_path\": nan_mask_save_path,\n",
    "#             \"nan_mask_data\": df_nan_mask,            \n",
    "#            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e932578-3bf1-4e8a-8b1a-916043158cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Path file present, overwriting.\n",
      "INFO:root:Saved (1446, 24) shaped data as dengue_features_clean.parquet\n",
      "INFO:root:Saved (1446, 4) shaped data as dengue_labels_clean.parquet\n",
      "INFO:root:Path file present, overwriting.\n",
      "INFO:root:Saved (1446, 11) shaped data as dengue_nan_mask.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 530 ms, sys: 8.05 ms, total: 538 ms\n",
      "Wall time: 537 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pipe_output = pipe_clean(overwrite_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f60343d5-29e1-4d2b-b9f5-976143ed890c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>iq</td>\n",
       "      <td>2001</td>\n",
       "      <td>22</td>\n",
       "      <td>2001-05-28</td>\n",
       "      <td>0.299943</td>\n",
       "      <td>0.302943</td>\n",
       "      <td>0.318714</td>\n",
       "      <td>0.387443</td>\n",
       "      <td>90.07</td>\n",
       "      <td>296.845714</td>\n",
       "      <td>...</td>\n",
       "      <td>20.3</td>\n",
       "      <td>91.465714</td>\n",
       "      <td>90.07</td>\n",
       "      <td>16.694286</td>\n",
       "      <td>8.8</td>\n",
       "      <td>27.25</td>\n",
       "      <td>12.65</td>\n",
       "      <td>34.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    city  year  weekofyear week_start_date   ndvi_ne   ndvi_nw   ndvi_se  \\\n",
       "977   iq  2001          22      2001-05-28  0.299943  0.302943  0.318714   \n",
       "\n",
       "      ndvi_sw  precipitation_amt_mm  reanalysis_air_temp_k  ...  \\\n",
       "977  0.387443                 90.07             296.845714  ...   \n",
       "\n",
       "     reanalysis_precip_amt_kg_per_m2  reanalysis_relative_humidity_percent  \\\n",
       "977                             20.3                             91.465714   \n",
       "\n",
       "     reanalysis_sat_precip_amt_mm  reanalysis_specific_humidity_g_per_kg  \\\n",
       "977                         90.07                              16.694286   \n",
       "\n",
       "     reanalysis_tdtr_k  station_avg_temp_c  station_diur_temp_rng_c  \\\n",
       "977                8.8               27.25                    12.65   \n",
       "\n",
       "     station_max_temp_c  station_min_temp_c  station_precip_mm  \n",
       "977                34.8                20.5               32.0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipe_output[\"X_clean_data\"].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed000090-7778-4283-aa4e-b5ef82a2404c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>sj</td>\n",
       "      <td>2006</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city  year  weekofyear  total_cases\n",
       "834   sj  2006          25            6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipe_output[\"y_clean_data\"].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bbddc2e-d69e-4110-93e4-bae55751ac79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ndvi_ne  ndvi_nw  ndvi_se  ndvi_sw  precipitation_amt_mm  \\\n",
       "1018    False    False    False    False                 False   \n",
       "\n",
       "      reanalysis_sat_precip_amt_mm  station_avg_temp_c  \\\n",
       "1018                         False               False   \n",
       "\n",
       "      station_diur_temp_rng_c  station_max_temp_c  station_min_temp_c  \\\n",
       "1018                    False               False               False   \n",
       "\n",
       "      station_precip_mm  \n",
       "1018              False  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipe_output[\"nan_mask_data\"].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e544a9be-729a-4cbb-9645-1992b59c4f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ndvi_ne                                  15.25\n",
       "ndvi_nw                                   5.63\n",
       "ndvi_se                                   3.71\n",
       "ndvi_sw                                   3.71\n",
       "precipitation_amt_mm                      2.40\n",
       "reanalysis_air_temp_k                     2.82\n",
       "reanalysis_avg_temp_k                     2.82\n",
       "reanalysis_dew_point_temp_k               2.88\n",
       "reanalysis_max_air_temp_k                 2.68\n",
       "reanalysis_min_air_temp_k                 2.61\n",
       "reanalysis_precip_amt_kg_per_m2           2.88\n",
       "reanalysis_relative_humidity_percent      2.88\n",
       "reanalysis_sat_precip_amt_mm              2.40\n",
       "reanalysis_specific_humidity_g_per_kg     2.88\n",
       "reanalysis_tdtr_k                         2.82\n",
       "station_avg_temp_c                        5.01\n",
       "station_diur_temp_rng_c                   5.01\n",
       "station_max_temp_c                        3.09\n",
       "station_min_temp_c                        2.68\n",
       "station_precip_mm                         2.61\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipe_output[\"X_capped_rows_prc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b89f8-c28c-4b47-b7b3-254d218ed752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba: py311_data_prep",
   "language": "python",
   "name": "py311_data_prep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
