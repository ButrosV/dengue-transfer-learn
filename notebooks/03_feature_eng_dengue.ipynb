{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da8cda4-d02f-4dff-a9ba-6ad1dbcc0bfd",
   "metadata": {},
   "source": [
    "# Feature Enginering Notebook for Dengue Transfer Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e0e19-aca2-4b40-9ad7-4401b8eb5def",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Dengue ML datasets track environmental and temporal factors influencing Aedes mosquito breeding and virus transmission in tropical regions like San Juan and Iquitos.\n",
    "\n",
    "- #### Temporal Features\n",
    "    - **city**: Location identifier (e.g., 'sj' for San Juan, 'iq' for Iquitos)—captures city-specific mosquito/dengue patterns.\n",
    "    - **year, weekofyear, week_start_date**: Time granularity for seasonality; dengue peaks during rainy seasons (weekofyear critical for lagged effects).\n",
    "\n",
    "- #### Vegetation Indices (NDVI)\n",
    "    - **ndvi_ne, ndvi_nw, ndvi_se, ndvi_sw**: Normalized Difference Vegetation Index by city quadrant. Higher NDVI indicates lush vegetation providing mosquito shade/breeding sites; key for Aedes habitat detection via satellite.\n",
    "\n",
    "- #### Precipitation \\& Water\n",
    "    - **precipitation_amt_mm**: Rainfall amount—creates standing water breeding sites.\n",
    "    - **reanalysis_precip_amt_kg_per_m2, reanalysis_sat_precip_amt_mm**: Reanalysis (modeled) precipitation variants confirming observed rain.\n",
    "    - **station_precip_mm**: Ground station measurements—most direct rain proxy.\n",
    "\n",
    "- #### Temperature Metrics\n",
    "    - **reanalysis_air_temp_k, reanalysis_avg_temp_k, reanalysis_max_air_temp_k, reanalysis_min_air_temp_k**: Reanalysis temps in Kelvin; optimal Aedes range 26-32°C accelerates larval development/virus replication.\n",
    "    - **station_avg_temp_c, station_max_temp_c, station_min_temp_c**: Station temps in Celsius—ground truth validation.\n",
    "    - **station_diur_temp_rng_c**: Diurnal range; wider swings stress mosquitoes.\n",
    "    - **reanalysis_tdtr_k**: Temperature diurnal temperature range (reanalysis).\n",
    "\n",
    "- #### Humidity \\& Moisture\n",
    "    - **reanalysis_dew_point_temp_k**: Dew point—direct humidity proxy; high values (>20°C) favor mosquito survival.\n",
    "    - **reanalysis_relative_humidity_percent**: Relative humidity %—critical for egg/larval viability.\n",
    "    - **reanalysis_specific_humidity_g_per_kg**: Absolute moisture content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8953d6-c281-4712-be9f-c8edd51d0155",
   "metadata": {},
   "source": [
    "### For a fair fight between LightGBM and our LSTM, both models will have the same starting lineup of features. These include seasonal cues, vegetation signals, missing data hints, and early low-case periods—everything else is just how each model likes to learn over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b498f8d-8129-4b55-bbdd-e05306eace30",
   "metadata": {},
   "source": [
    "### Notebook sections for the third project notebook (Feature Enginering/Selection/)\n",
    "1. Get Data\n",
    "2. Feature Engineering\n",
    "    - Common for both models\n",
    "    - Model specific:\n",
    "        - LightGBM benchmark\n",
    "        - LSTM\n",
    "3. Feature Selection\n",
    "4. Target processing\n",
    "5. Benchmark model (TBC, poss notebook 04)\n",
    "7. Model Tuning  (TBC)\n",
    "8. Model Evaluation  (TBC, poss notebook 04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bfe30a2-648d-47ab-b959-f2ba4b1cb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Any, Dict, Optional\n",
    "import gc\n",
    "import itertools\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set one level up as project root|\n",
    "if os.path.abspath(\"..\") not in sys.path:\n",
    "    sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "    \n",
    "from src.config import ProjectConfig  # project config file parser\n",
    "from src.utils.eda import value_streaks, top_correlations\n",
    "from src.utils.visualizations import (compute_correlations_matrix,\n",
    "                display_distributions, random_color, random_colormap,\n",
    "                display_timeseries)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "from src.utils.eda import top_correlations, top_vif\n",
    "from src.utils.utils import _check_feature_presence, load_file, save_file\n",
    "from src.preprocessing.clean import (drop_nan_rows, cap_outliers,\n",
    "                                    median_groupwise_impute, pipe_clean)\n",
    "\n",
    "from src.preprocessing.engineer import (reduce_features,\n",
    "                                        add_missingness_features,\n",
    "                                        low_value_targets,\n",
    "                                        circular_time_features)\n",
    "\n",
    "from src.preprocessing.select import remove_features\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "# from matplotlib.axis import Axis\n",
    "# from matplotlib.dates import MonthLocator, YearLocator, DateFormatter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae2f1da-75c3-4319-b3a9-8f2cca5c68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnfg = ProjectConfig.load_configuration()\n",
    "PATH_TO_RAW_DATA = cnfg.data.dirs[\"raw\"]\n",
    "PATH_TO_INTERMEDIATE_DATA = cnfg.data.dirs[\"intermediate\"]\n",
    "\n",
    "FILE_TRAIN_RAW= cnfg.data.files[\"features_train\"]\n",
    "FILE_TEST_RAW = cnfg.data.files[\"features_test\"]\n",
    "FILE_LABELS_RAW = cnfg.data.files[\"labels_train\"]\n",
    "\n",
    "PATH_TO_INTERMEDIATE_DATA = cnfg.data.dirs[\"intermediate\"]\n",
    "FILE_NAN_CLEAN = cnfg.data.files[\"nan_mask\"]\n",
    "FILE_TRAIN_CLEAN = cnfg.data.files[\"features_clean\"]\n",
    "FILE_LABELS_CLEAN = cnfg.data.files[\"labels_clean\"]\n",
    "\n",
    "TARGET = cnfg.preprocess.feature_groups[\"target\"]\n",
    "ENV_FEAT_PREFIX = cnfg.preprocess.feature_groups[\"env_prefixes\"]\n",
    "CITYGROUP_FEAT = cnfg.preprocess.feature_groups[\"city\"]\n",
    "WEEK_FEAT = cnfg.preprocess.feature_groups[\"week\"]\n",
    "DATETIME_FEAT = cnfg.preprocess.feature_groups[\"datetime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2a46ad-09f5-4c50-8a6d-dabb2dd219e6",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a0fe74-0b18-455d-89be-57390d768ffc",
   "metadata": {},
   "source": [
    "- Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a8f874-3dbe-41fb-bb5d-ef8fed24036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = load_file(path=PATH_TO_RAW_DATA / FILE_TRAIN_RAW, datetime_col=DATETIME_FEAT)\n",
    "df_test_raw = load_file(path=PATH_TO_RAW_DATA / FILE_TEST_RAW, datetime_col=DATETIME_FEAT)\n",
    "df_labels_raw = load_file(path=PATH_TO_RAW_DATA / FILE_LABELS_RAW)\n",
    "list_raw_df = [df_train_raw, df_test_raw, df_labels_raw]\n",
    "env_features = [f for f in df_train_raw if f.startswith(tuple(ENV_FEAT_PREFIX))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff0e11-bb6e-4f00-8f38-46830709172f",
   "metadata": {},
   "source": [
    "- Cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8b7162-23de-4590-ad08-adea8d395e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # use pipeline output\n",
    "# cleaned_data = pipe_clean(overwrite_files=True)\n",
    "# df_train_clean = cleaned_data[\"X_clean_data\"]\n",
    "# df_labels_clean = cleaned_data[\"y_clean_data\"]\n",
    "# df_nan_mask = cleaned_data[\"nan_mask_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1009c3b4-939f-4f01-ad2f-872647b5c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.2 ms, sys: 5.87 ms, total: 46.1 ms\n",
      "Wall time: 45.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# or just load from disc:\n",
    "df_train_clean = load_file(path=PATH_TO_INTERMEDIATE_DATA / FILE_TRAIN_CLEAN, datetime_col=DATETIME_FEAT)\n",
    "df_labels_clean = load_file(path=PATH_TO_INTERMEDIATE_DATA / FILE_LABELS_CLEAN)\n",
    "df_nan_mask = load_file(path=PATH_TO_INTERMEDIATE_DATA / FILE_NAN_CLEAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193350c-2c33-418a-89b7-f8344e227ab1",
   "metadata": {},
   "source": [
    "## Common engineering baseline\n",
    "- [X] Missingness features\n",
    "- [X] combine north and south NDVIs\n",
    "- [X] Process zero/low value target value streaks (add `iq_initial_low_case_streak` feature)\n",
    "- [ ] Cyclical time features\n",
    "- [ ] (Optional) Lags / rolling stats\n",
    "    - Environmental station features 1-2 lags each (t-1, if feature space allows add t-2)\n",
    "    - Cumulative effects (rainfall, precipitation) - rolling sum (4 weeks)\n",
    "    - NDVI missingness: 1-2 lags (t-1, if feature space allows  t-4)\n",
    "    - Station missingness: 1 lag (t-1)\n",
    "    - if feature space bloats - replace lags with single rolling stat\n",
    "- [ ] RobustScaler (features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d65167-dd66-4e37-9385-0e9791fd74ce",
   "metadata": {},
   "source": [
    "### Add data misingness features\n",
    "- Add missigness features that flag NaN rows for top NaN columns that have NaN rate above 1 %:\n",
    "    - Idea - models, especially `LSTM` may learn from informatioun that \"this datapoint was missing\"\n",
    "- [X] grouped `ndvi_n_missing` and `ndvi_s_missing` (`ndvi_n` and `ndvi_s` will be grouped downstream)\n",
    "    - if feature space bloats - combine in single `ndvi_missing`\n",
    "- [X] `station_missing` - group all station data missing flags (\"station\", \"precipitation\" prefixes)\n",
    "- [X] `missing_pct_env_feat`:\n",
    "    - normalized aggregation of all missing feature count/NaNs at a timestamp relative to a fixed set of core environmental variables, signals overall source data uncertainty.\n",
    "    -  if feature space bloats - drop entirely\n",
    "- [ ] (Optional) During SJ pretraining: Slightly stronger dropout on missingness features than on base features to hide city-correlated missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd11835-d204-4956-84d1-45c1c3de1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO remove after cleaning\n",
    "\n",
    "# def add_missingness_features(X: pd.DataFrame,\n",
    "#                              nan_mask: pd.DataFrame,\n",
    "#                              aggregated_feat_name: Optional[str]=None,\n",
    "#                              input_env_feat_prefixes: Optional[List[str]]=None,\n",
    "#                              input_group_prefix: Optional[list]=None,\n",
    "#                              output_feature_prefix: Optional[str]=None\n",
    "#                             ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Add missingness indicator features to DataFrame using column prefix patterns.\n",
    "#     1. (optional) Aggregated ratio of missing values across environment prefix columns.\n",
    "#     2. Max missingness indicator (0/1) per feature group defined by prefixes\n",
    "#     Fall back to config values if parameters unspecified.\n",
    "#     :param X: Input DataFrame to add missingness features to.\n",
    "#     :param nan_mask: Boolean DataFrame same shape as X where True indicates missing.\n",
    "#     :param aggregated_feat_name: Name for aggregated missingness ratio feature. \n",
    "#                                 Uses config default if None.\n",
    "#     :param input_env_feat_prefixes: List of prefixes to match environment columns \n",
    "#                                    for aggregated ratio. Uses config if None.\n",
    "#     :param input_group_prefix: List of prefix lists or single strings defining \n",
    "#                               feature groups for max missingness indicators. \n",
    "#                               Mixed format supported: `[[\"station\", \"precip\"], \"ndvi_s\"]`.\n",
    "#                               Uses config if None.\n",
    "#     :param output_feature_prefix: Prefix for new group missingness columns \n",
    "#                                  (e.g., \"missing_station_max\"). Uses config if None.\n",
    "#     :return: X with additional missingness feature column(s).\n",
    "#     :raises ValueError: If no columns match environment prefixes.\n",
    "#     \"\"\"\n",
    "#     X_missing = X.copy()\n",
    "#     config = cnfg.preprocess.missingness_features\n",
    "#     aggregated_feat_name = aggregated_feat_name or config.get(\"aggregated_feat_n\")\n",
    "#     input_env_feat_prefixes = input_env_feat_prefixes or cnfg.preprocess.feature_groups[\"env_prefixes\"]\n",
    "#     input_group_prefix = input_group_prefix or config[\"group_prefixes\"]\n",
    "#     output_feature_prefix = output_feature_prefix or config[\"new_feature_prefix\"]\n",
    "\n",
    "#     if aggregated_feat_name and input_env_feat_prefixes:\n",
    "#         env_cols = nan_mask.columns[nan_mask.columns.str.startswith(tuple(input_env_feat_prefixes))]\n",
    "#         denominator = len(env_cols)\n",
    "#         if denominator == 0:\n",
    "#             raise ValueError(\"No columns match environment prefix/es '{input_env_feat_prefixes}'.\")\n",
    "#         X_missing[f\"{output_feature_prefix}{aggregated_feat_name}\"\n",
    "#             ] = nan_mask[env_cols].sum(axis=1) / denominator\n",
    "\n",
    "#     for prefix in input_group_prefix:\n",
    "#         if isinstance(prefix, str):\n",
    "#             prefix = [prefix]\n",
    "#         features = nan_mask.columns[\n",
    "#             nan_mask.columns.str.startswith(tuple(prefix))]\n",
    "#         if len(features) == 0:\n",
    "#             logging.warning(f\"No columns match prefix/es '{prefix}' - skipping.\")\n",
    "#             continue\n",
    "#         feature_name = f\"{output_feature_prefix}{prefix[0]}\"\n",
    "#         X_missing[feature_name] = nan_mask[features].agg(\"max\", axis=1)\n",
    "    \n",
    "#     return X_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a7f774-85b5-4a25-958e-feb4dd4cc033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['missing_pct_env_feat', 'missing_station', 'missing_ndvi_s',\n",
       "       'missing_ndvi_n'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_eng = add_missingness_features(X=df_train_clean, nan_mask=df_nan_mask)\n",
    "df_train_eng.columns[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb33f7-f3c6-4f88-884a-12242f94d51d",
   "metadata": {},
   "source": [
    "### Combine north and south NDVIs\n",
    "- [X] combine primary veatures (method `mean`)\n",
    "- [X] combine related misingness flags (method `max`) - done upstream in `add_missingness_features()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06273932-2d54-4799-bd9d-336c22c87c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO remove after cleaning\n",
    "\n",
    "# def reduce_features(X: pd.DataFrame, \n",
    "#                     input_feat_groups: List[List[str]]=None,\n",
    "#                     output_feat_names: List[str]=None,\n",
    "#                    function: str=None):\n",
    "#     \"\"\"\n",
    "#     Aggregate multiple feature groups into single reduced features using specified function.\n",
    "#     Combine input features and drop originals.\n",
    "    \n",
    "#     :param X: Input pandas DataFrame.\n",
    "#     :param input_feat_groups: List of feature group lists to aggregate. Default None uses \n",
    "#            config.yaml settings (e.g., [['ndvi_ne', 'ndvi_nw']]).\n",
    "#     :param output_feat_names: Output column names for aggregated features. Default None uses \n",
    "#            config.yaml settings (e.g., ['ndvi_north']).\n",
    "#     :param function: Aggregation function string ('mean', 'sum', 'median'). Default None uses \n",
    "#            config.yaml settings (e.g 'mean').\n",
    "#     :return: DataFrame with reduced features. Original input columns dropped.\n",
    "#     \"\"\"\n",
    "#     X_reduced = X.copy()\n",
    "#     if input_feat_groups is None:\n",
    "#         input_feat_groups = cnfg.preprocess.combine_features[\"input_groups\"]\n",
    "#     if output_feat_names is None:\n",
    "#         output_feat_names = cnfg.preprocess.combine_features[\"output_names\"]\n",
    "#     if function is None:\n",
    "#         function = cnfg.preprocess.combine_features[\"aggregation\"]\n",
    "\n",
    "        \n",
    "#     if not len(input_feat_groups) == len(output_feat_names):\n",
    "#         raise ValueError(f\"Input feature groups {input_feat_groups} mismatch target keys {output_feat_names}\")\n",
    "#     missing_features = set(itertools.chain(*input_feat_groups)) - set(X.columns)\n",
    "#     if missing_features:\n",
    "#         raise ValueError(f\"No {missing_features} features in input dataframe columns: {X.columns}\")\n",
    "\n",
    "#     for name, group in zip(output_feat_names, input_feat_groups):\n",
    "#         X_reduced[name] = X_reduced[group].agg(function, axis=1)\n",
    "#         X_reduced.drop(columns=group, inplace=True)\n",
    "        \n",
    "#     return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2635724-4cbd-49b0-9a90-9eb0a4d91e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ndvi_north', 'ndvi_south']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_eng = reduce_features(df_train_eng)\n",
    "[f for f in df_train_eng.columns if f.startswith(\"ndvi\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be842fb0-6c0c-450b-9f3c-f95737626509",
   "metadata": {},
   "source": [
    "### Process zero/low value target value streaks\n",
    "- [X] Feature engineer continuous low case streak counts for entire period's low values (ie `low_case_streak`)\n",
    "- [X] Feature engineer binary low case streak marker for early low values (ie `initial_low_case_streak`)\n",
    "- [X] avoid target leakage (do not use future data in calculating streaks - i.e. `zero_one_targets` function used for EDA)\n",
    "- [ ] compare performance with and without `low_case_streak` and `initial_low_case_streak` features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec01639-b042-4cd9-b88e-05c1c35cc942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_streak_len_threshold': 26,\n",
       " 'target_streak_feat_n': 'low_case_streak',\n",
       " 'initial_streaks': True,\n",
       " 'low_value_range': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_val_feats = cnfg.preprocess.low_value_streak_features\n",
    "low_val_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a99e7e8c-8f1c-4467-ba63-ed7f849fe362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero and one consecutive value streaks for target data (total dengue cases).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_pos</th>\n",
       "      <th>last_pos</th>\n",
       "      <th>streak_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930</td>\n",
       "      <td>1004</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073</td>\n",
       "      <td>1081</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1089</td>\n",
       "      <td>1094</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1339</td>\n",
       "      <td>1344</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1196</td>\n",
       "      <td>1200</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1238</td>\n",
       "      <td>1240</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1098</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1264</td>\n",
       "      <td>1266</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1335</td>\n",
       "      <td>1337</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1388</td>\n",
       "      <td>1389</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1419</td>\n",
       "      <td>1420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1409</td>\n",
       "      <td>1410</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1397</td>\n",
       "      <td>1398</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>512</td>\n",
       "      <td>513</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>518</td>\n",
       "      <td>519</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>772</td>\n",
       "      <td>773</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>627</td>\n",
       "      <td>628</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1443</td>\n",
       "      <td>1444</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first_pos  last_pos  streak_len\n",
       "0         930      1004          75\n",
       "1        1073      1081           9\n",
       "2        1089      1094           6\n",
       "3        1339      1344           6\n",
       "4        1196      1200           5\n",
       "5        1238      1240           3\n",
       "6        1098      1100           3\n",
       "7        1264      1266           3\n",
       "8        1335      1337           3\n",
       "9        1388      1389           2\n",
       "10       1419      1420           2\n",
       "11       1409      1410           2\n",
       "12       1397      1398           2\n",
       "13        512       513           2\n",
       "14        518       519           2\n",
       "15        772       773           2\n",
       "16        627       628           2\n",
       "17       1443      1444           2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_one_targets = value_streaks(data=df_labels_clean, column=TARGET, value=range(2),\n",
    "                             run_threshold=1)\n",
    "print(\"Zero and one consecutive value streaks for target data (total dengue cases).\")\n",
    "zero_one_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "833cf30c-6bc4-4139-8885-2033fc4f2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_cumulative_streaks(group: pd.Series,\n",
    "#                             low_value_range:int,\n",
    "#                            filter_initial_streaks: bool=False):\n",
    "#     \"\"\"\n",
    "#     Compute low-value streak lengths within a 1D series, optionally filtering to initial streak only.\n",
    "\n",
    "#     :param group: pandas Series representing a single grouped sequence (e.g., one city).\n",
    "#     :param low_value_range: Upper bound (exclusive) for values considered \"low\".\n",
    "#     :param filter_initial_streaks: If True, keep only initial low-value streak when it starts at first\n",
    "#                                    position (all others 0). If False, return complete streak lengths.\n",
    "#                                    Default is False.\n",
    "#     :return: pandas Series (same index/shape as `group`) with cumulative low-value streak lengths,\n",
    "#              filtered according to `filter_initial_streaks`.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     mask_lows = group.isin(range(low_value_range))\n",
    "#     streak_groups = (mask_lows != mask_lows.shift(fill_value=False)).cumsum()\n",
    "#     low_count_streaks = mask_lows.groupby(by=streak_groups).cumsum()\n",
    "\n",
    "#     if not filter_initial_streaks:\n",
    "#         return low_count_streaks\n",
    "\n",
    "#     else:\n",
    "#         if low_count_streaks.iloc[0] == 1:\n",
    "#             initial_low_streaks = low_count_streaks.where(streak_groups == 1, 0)\n",
    "#         else:\n",
    "#             initial_low_streaks = pd.Series(0, index=low_count_streaks.index)\n",
    "#         return initial_low_streaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44f77d7f-2124-4cf6-9354-0822487328cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def low_value_targets(X: pd.DataFrame, y: pd.DataFrame,\n",
    "#                       target_feature: str | None=None,\n",
    "#                       group_feature:str | None=None,\n",
    "#                       new_feat_name:str | None=None,\n",
    "#                       initial_streaks_only:bool | None=None,\n",
    "#                       min_initial_streak_len:int | None=None,\n",
    "#                       low_value_range:int | None=None\n",
    "#                      ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Generate low-value streak features for ML pipelines. Creates continuous streak length feature\n",
    "#     (`low_case_streak`) and optional boolean initial-streak indicator with minimum length filtering.\n",
    "    \n",
    "#     Continuous streak preserves magnitude info for model gradients. Boolean initial streak supports\n",
    "#     minimum length thresholding.\n",
    "\n",
    "#     :param X: Input features DataFrame.\n",
    "#     :param y: Target DataFrame (same index as X).\n",
    "#     :param target_feature: Target column name. Uses config default if None.\n",
    "#     :param group_feature: Grouping column (e.g., 'city'). None processes entire series.\n",
    "#                             Defaults to config settings.\n",
    "#     :param new_feat_name: Output base name (e.g., 'low_case_streak'). None returns X unchanged.\n",
    "#                             Defaults to config settings.\n",
    "#     :param initial_streaks_only: If True, adds thresholded boolean `initial_{new_feat_name}`.\n",
    "#                             Defaults to config settings.\n",
    "#     :param min_initial_streak_len: Min length threshold. Applies **only** to boolean `initial_*` feature.\n",
    "#                             Defaults to config settings.\n",
    "#     :param low_value_range: Values < this are \"low\" (exclusive upper bound).\n",
    "#                             Defaults to config settings.\n",
    "#     :return: X with `low_case_streak` (continuous) ± `initial_low_case_streak` (boolean).\n",
    "#     \"\"\"\n",
    "    \n",
    "#     assert all(X.index == y.index), \"Indices for 'X' and 'y' must be aligned.\" \n",
    "    \n",
    "#     config_values = cnfg.preprocess\n",
    "    \n",
    "#     target_feature = target_feature or config_values.feature_groups[\"target\"]\n",
    "#     group_feature = group_feature or config_values.feature_groups[\"city\"]\n",
    "#     min_initial_streak_len = min_initial_streak_len or (config_values.\n",
    "#         low_value_streak_features[\"target_streak_len_threshold\"])\n",
    "#     new_feat_name = new_feat_name or (config_values.\n",
    "#         low_value_streak_features.get(\"target_streak_feat_n\"))\n",
    "#     low_value_range = low_value_range or (config_values.\n",
    "#         low_value_streak_features[\"low_value_range\"])\n",
    "\n",
    "#     if initial_streaks_only is None:\n",
    "#         initial_streaks_only = config_values.low_value_streak_features.get(\"initial_streaks\"\n",
    "#                                                                           ) or False\n",
    "#     if new_feat_name is None:\n",
    "#         return X\n",
    "        \n",
    "#     X_low_streaks = X.copy()\n",
    "\n",
    "#     if group_feature is not None:\n",
    "#         low_count_streaks = y.groupby(by=group_feature)[target_feature].transform(\n",
    "#             lambda x: _get_cumulative_streaks(x, low_value_range))\n",
    "#     else:\n",
    "#         low_count_streaks = _get_cumulative_streaks(y[target_feature], low_value_range)\n",
    "        \n",
    "#     temp_output_dict = {new_feat_name: low_count_streaks}\n",
    "\n",
    "#     if initial_streaks_only:\n",
    "#         if group_feature is not None:\n",
    "#             initial_streaks = y.groupby(by=group_feature)[target_feature].transform(\n",
    "#                 lambda x: _get_cumulative_streaks(x, low_value_range, initial_streaks_only))\n",
    "#         else:\n",
    "#             initial_streaks = _get_cumulative_streaks(y[target_feature], low_value_range,\n",
    "#                                                       initial_streaks_only)\n",
    "            \n",
    "#         if min_initial_streak_len:\n",
    "#             long_streak_mask = initial_streaks >= min_initial_streak_len\n",
    "#             long_strek_threshpoints = long_streak_mask[\n",
    "#                 initial_streaks == min_initial_streak_len].index\n",
    "            \n",
    "#             for point in long_strek_threshpoints:\n",
    "#                 start = max(0, point - min_initial_streak_len + 1)\n",
    "#                 long_streak_mask[start:point] = True\n",
    "#             initial_streaks = initial_streaks.where(long_streak_mask, 0)\n",
    "            \n",
    "#         temp_output_dict[f\"initial_{new_feat_name}\"] = initial_streaks\n",
    "            \n",
    "            \n",
    "#     for feat_name, streak in temp_output_dict.items():\n",
    "#         if feat_name.startswith(\"initial_\"):\n",
    "#             streak = streak.astype(bool).astype(int)\n",
    "#         X_low_streaks[feat_name] = streak\n",
    "        \n",
    "#     return X_low_streaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76aa8850-8d54-43b1-abc1-d43ca795ab5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'year', 'weekofyear', 'week_start_date', 'precipitation_amt_mm',\n",
       "       'reanalysis_air_temp_k', 'reanalysis_avg_temp_k',\n",
       "       'reanalysis_dew_point_temp_k', 'reanalysis_max_air_temp_k',\n",
       "       'reanalysis_min_air_temp_k', 'reanalysis_precip_amt_kg_per_m2',\n",
       "       'reanalysis_relative_humidity_percent', 'reanalysis_sat_precip_amt_mm',\n",
       "       'reanalysis_specific_humidity_g_per_kg', 'reanalysis_tdtr_k',\n",
       "       'station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c',\n",
       "       'station_min_temp_c', 'station_precip_mm', 'missing_pct_env_feat',\n",
       "       'missing_station', 'missing_ndvi_s', 'missing_ndvi_n', 'ndvi_north',\n",
       "       'ndvi_south', 'low_case_streak', 'initial_low_case_streak'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_eng = low_value_targets(X=df_train_eng, y=df_labels_clean)\n",
    "df_train_eng.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db751e30-582f-401b-9ea0-62641b478883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_eng[\"initial_low_case_streak\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d61718e2-8231-4535-8dee-7d5deef4883b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3029"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_eng[\"low_case_streak\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6b52c-cb45-4b93-928e-ebcede43fe8a",
   "metadata": {},
   "source": [
    "### Cyclical time features\n",
    "- [X] Create circular sin/cos features based on `weekofyear`\n",
    "- [X] drop source time feature `weekofyear`\n",
    "- [X] keep `week_start_date` for time being for train-test-splits and windowing\n",
    "- [ ] remove `week_start_date` before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27c7163f-50bc-4d3a-8da4-a21c2a64971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def circular_time_features(X: pd.DataFrame,\n",
    "#                            source_feature: str | None = None,\n",
    "#                            period: int | None = None,\n",
    "#                            drop_source_feature: bool = True):\n",
    "#     \"\"\"\n",
    "#     Generate cyclical sin/cos features for periodic time variables. Transforms integer week/month/day\n",
    "#     features into continuous circular encodings that preserve temporal continuity across period boundaries.\n",
    "\n",
    "#     :param X: Input features DataFrame.\n",
    "#     :param source_feature: Periodic column name (e.g., 'weekofyear'). Uses config default if None.\n",
    "#     :param period: Fixed cycle length (e.g., 52 for weeks, 12 for months). Uses column max if None.\n",
    "#     :param drop_source_feature: If True, drops original source column after encoding.\n",
    "#     :return: X with `sin_{source_feature}` and `cos_{source_feature}` columns added.\n",
    "#     \"\"\"\n",
    "#     source_feature = (source_feature \n",
    "#                       or cnfg.preprocess.feature_groups[\"week\"])\n",
    "    \n",
    "#     _check_feature_presence(source_feature, X.columns)\n",
    "    \n",
    "#     X_circular = X.copy()\n",
    "#     divisor = period or X_circular[source_feature].max()\n",
    "    \n",
    "#     X_circular[f\"sin_{source_feature}\"] = np.sin(\n",
    "#         2 * np.pi * X_circular[source_feature] / divisor)\n",
    "#     X_circular[f\"cos_{source_feature}\"] = np.cos(\n",
    "#         2 * np.pi * X_circular[source_feature] / divisor)\n",
    "\n",
    "#     if drop_source_feature:\n",
    "#         X_circular.drop(columns=[source_feature], inplace=True)\n",
    "\n",
    "#     return X_circular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e09cc13-c104-49fd-8fde-3ba9b20fdfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['week_start_date', 'sin_weekofyear', 'cos_weekofyear']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_eng = circular_time_features(df_train_eng)\n",
    "[feature for feature in df_train_eng.columns if \"week\" in feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a447a-376d-4694-b773-d9521b38c72a",
   "metadata": {},
   "source": [
    "## Common Feature Selection baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367babf2-d259-48e7-8514-75825a19e1d8",
   "metadata": {},
   "source": [
    "### Remove selected multicolinear features\n",
    "- [X] Remove initial `config.yaml` milticolinear features form dataframe\n",
    "    - Initial assesment of pairwise correlations in EDA \n",
    "- [X] Assess city-wise VIF to EDA instead of correlation matrix for one-vs-all relationships.\n",
    "- [ ] Remove features with VIF > 10\n",
    "- [X] always prefer station_* over reanalysis_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a1a6d78-409e-4ffd-9d54-3113201f3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO remove after cleaning\n",
    "\n",
    "# def reduce_features(X: pd.DataFrame, \n",
    "#                     input_feat_groups: List[List[str]]=None,\n",
    "#                     output_feat_names: List[str]=None,\n",
    "#                    function: str=None):\n",
    "#     \"\"\"\n",
    "#     Aggregate multiple feature groups into single reduced features using specified function.\n",
    "#     Combine input features and drop originals.\n",
    "    \n",
    "#     :param X: Input pandas DataFrame.\n",
    "#     :param input_feat_groups: List of feature group lists to aggregate. Default None uses \n",
    "#            config.yaml settings (e.g., [['ndvi_ne', 'ndvi_nw']]).\n",
    "#     :param output_feat_names: Output column names for aggregated features. Default None uses \n",
    "#            config.yaml settings (e.g., ['ndvi_north']).\n",
    "#     :param function: Aggregation function string ('mean', 'sum', 'median'). Default None uses \n",
    "#            config.yaml settings (e.g 'mean').\n",
    "#     :return: DataFrame with reduced features. Original input columns dropped.\n",
    "#     \"\"\"\n",
    "#     X_reduced = X.copy()\n",
    "#     if input_feat_groups is None:\n",
    "#         input_feat_groups = cnfg.preprocess.combine_features[\"input_groups\"]\n",
    "#     if output_feat_names is None:\n",
    "#         output_feat_names = cnfg.preprocess.combine_features[\"output_names\"]\n",
    "#     if function is None:\n",
    "#         function = cnfg.preprocess.combine_features[\"aggregation\"]\n",
    "\n",
    "        \n",
    "#     if not len(input_feat_groups) == len(output_feat_names):\n",
    "#         raise ValueError(f\"Input feature groups {input_feat_groups} mismatch target keys {output_feat_names}\")\n",
    "#     missing_features = set(itertools.chain(*input_feat_groups)) - set(X.columns)\n",
    "#     if missing_features:\n",
    "#         raise ValueError(f\"No {missing_features} features in input dataframe columns: {X.columns}\")\n",
    "\n",
    "#     for name, group in zip(output_feat_names, input_feat_groups):\n",
    "#         X_reduced[name] = X_reduced[group].agg(function, axis=1)\n",
    "#         X_reduced.drop(columns=group, inplace=True)\n",
    "        \n",
    "#     return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d144effe-e718-46dc-b8ce-7a47f86ad402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reanalysis_sat_precip_amt_mm',\n",
       " 'reanalysis_dew_point_temp_k',\n",
       " 'reanalysis_air_temp_k',\n",
       " 'reanalysis_specific_humidity_g_per_kg',\n",
       " 'reanalysis_avg_temp_k',\n",
       " 'reanalysis_max_air_temp_k',\n",
       " 'reanalysis_min_air_temp_k']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnfg.preprocess.multicolinear[\"removal_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "251b5d9e-4e25-4ecb-8fb6-de1ad4687f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO remove after cleaning\n",
    "# def top_vif(data: pd.DataFrame):\n",
    "#     \"\"\"\n",
    "#     Calculate and return Variance Inflation Factor (VIF) scores for numeric features.\n",
    "    \n",
    "#     :param data: pandas DataFrame containing numeric and non-numeric features.\n",
    "#     :return: pandas DataFrame with features and their VIF scores,\n",
    "#                 sorted descending (excludes constant).\n",
    "#     \"\"\"\n",
    "#     data_vif = add_constant(data.select_dtypes(include=\"number\"))\n",
    "#     cols = data_vif.columns\n",
    "#     if data_vif.isna().sum().sum() > 1:\n",
    "#         raise ValueError(f\"{data_vif.isna().sum().sum()} NaNs in the dataframe.\")\n",
    "#     data_vif = [variance_inflation_factor(\n",
    "#         data_vif.values, i) for i in range(data_vif.shape[1])]\n",
    "#     data_vif = pd.DataFrame(data=data_vif, index=cols, columns=[\"vif\"])\n",
    "#     data_vif = data_vif.sort_values(by=\"vif\", ascending=False,\n",
    "#                                     na_position=\"first\").drop(index=\"const\")\n",
    "    \n",
    "#     return data_vif    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ae799aa-c3fa-460b-9b38-53f59901ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT DO CAPPING, LOG TRANSFORM INSTEAD\n",
    "# intermediate_target = cap_outliers(data=df_labels_raw, features=TARGET)\n",
    "# df_labels_clean = intermediate_target[\"data\"]\n",
    "# df_labels_log = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59424303-0035-4fa4-bcd8-5ae9052ccd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_distributions(data = df_labels_log,\n",
    "#                       hue_palette=(CITYGROUP_FEAT, random_colormap()),\n",
    "#                      features=[TARGET], title_prefix=TARGET.capitalize(),\n",
    "#                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b21a948f-28be-43d4-ac57-ce831c133694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/butros/miniconda3/envs/py311_data_prep/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "/home/butros/miniconda3/envs/py311_data_prep/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "/home/butros/miniconda3/envs/py311_data_prep/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/butros/miniconda3/envs/py311_data_prep/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vif_iq</th>\n",
       "      <th>vif_sj</th>\n",
       "      <th>vif_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initial_low_case_streak</th>\n",
       "      <td>5.011947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.039308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <td>455.592262</td>\n",
       "      <td>1698.333029</td>\n",
       "      <td>465.313920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <td>77.742075</td>\n",
       "      <td>1138.869614</td>\n",
       "      <td>185.239521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <td>419.607530</td>\n",
       "      <td>525.113549</td>\n",
       "      <td>383.644881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <td>114.996983</td>\n",
       "      <td>306.044563</td>\n",
       "      <td>212.880313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <td>37.573909</td>\n",
       "      <td>274.564065</td>\n",
       "      <td>66.793850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <td>3.350385</td>\n",
       "      <td>24.573056</td>\n",
       "      <td>4.341595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_min_air_temp_k</th>\n",
       "      <td>5.522143</td>\n",
       "      <td>19.140116</td>\n",
       "      <td>23.767917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_max_air_temp_k</th>\n",
       "      <td>5.854910</td>\n",
       "      <td>17.221267</td>\n",
       "      <td>26.408432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <td>2.713163</td>\n",
       "      <td>10.093394</td>\n",
       "      <td>2.263844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <td>3.011444</td>\n",
       "      <td>9.138199</td>\n",
       "      <td>3.661123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <td>16.018138</td>\n",
       "      <td>3.437384</td>\n",
       "      <td>45.616386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <td>3.247666</td>\n",
       "      <td>3.337355</td>\n",
       "      <td>4.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
       "      <td>2.029493</td>\n",
       "      <td>2.850359</td>\n",
       "      <td>2.074169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1.844605</td>\n",
       "      <td>2.607606</td>\n",
       "      <td>1.942138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekofyear</th>\n",
       "      <td>1.370651</td>\n",
       "      <td>2.005518</td>\n",
       "      <td>1.528955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_precip_mm</th>\n",
       "      <td>1.315066</td>\n",
       "      <td>1.979482</td>\n",
       "      <td>1.483051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi_north</th>\n",
       "      <td>4.314284</td>\n",
       "      <td>1.417173</td>\n",
       "      <td>7.152458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi_south</th>\n",
       "      <td>4.498137</td>\n",
       "      <td>1.129208</td>\n",
       "      <td>9.853819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_case_streak</th>\n",
       "      <td>3.835010</td>\n",
       "      <td>1.048769</td>\n",
       "      <td>6.516656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_pct_env_feat</th>\n",
       "      <td>1.074091</td>\n",
       "      <td>1.043120</td>\n",
       "      <td>1.034225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           vif_iq       vif_sj   vif_total\n",
       "initial_low_case_streak                  5.011947          NaN   10.039308\n",
       "reanalysis_sat_precip_amt_mm                  inf          inf         inf\n",
       "precipitation_amt_mm                          inf          inf         inf\n",
       "reanalysis_dew_point_temp_k            455.592262  1698.333029  465.313920\n",
       "reanalysis_air_temp_k                   77.742075  1138.869614  185.239521\n",
       "reanalysis_specific_humidity_g_per_kg  419.607530   525.113549  383.644881\n",
       "reanalysis_relative_humidity_percent   114.996983   306.044563  212.880313\n",
       "reanalysis_avg_temp_k                   37.573909   274.564065   66.793850\n",
       "station_avg_temp_c                       3.350385    24.573056    4.341595\n",
       "reanalysis_min_air_temp_k                5.522143    19.140116   23.767917\n",
       "reanalysis_max_air_temp_k                5.854910    17.221267   26.408432\n",
       "station_min_temp_c                       2.713163    10.093394    2.263844\n",
       "station_max_temp_c                       3.011444     9.138199    3.661123\n",
       "reanalysis_tdtr_k                       16.018138     3.437384   45.616386\n",
       "station_diur_temp_rng_c                  3.247666     3.337355    4.018913\n",
       "reanalysis_precip_amt_kg_per_m2          2.029493     2.850359    2.074169\n",
       "year                                     1.844605     2.607606    1.942138\n",
       "weekofyear                               1.370651     2.005518    1.528955\n",
       "station_precip_mm                        1.315066     1.979482    1.483051\n",
       "ndvi_north                               4.314284     1.417173    7.152458\n",
       "ndvi_south                               4.498137     1.129208    9.853819\n",
       "low_case_streak                          3.835010     1.048769    6.516656\n",
       "missing_pct_env_feat                     1.074091     1.043120    1.034225"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_vif_pre = df_train_eng.groupby(by=CITYGROUP_FEAT).apply(lambda group: top_vif(data=group), include_groups=False)\n",
    "temp_vif_pre =  temp_vif_pre.loc[\"iq\"].join(temp_vif_pre.loc[\"sj\"], lsuffix=\"_iq\", rsuffix=\"_sj\", how=\"inner\")\n",
    "temp_vif_pre[\"vif_total\"] = top_vif(data=df_train_eng).values\n",
    "temp_vif_pre.sort_values(by=\"vif_sj\", ascending=False, na_position=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a13a6be6-a6ad-4223-a518-786540a73438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean = remove_features(X=df_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96df8cd4-cfeb-4211-a268-f9ba92f66ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vif_iq</th>\n",
       "      <th>vif_sj</th>\n",
       "      <th>vif_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <td>2.903773</td>\n",
       "      <td>15.205912</td>\n",
       "      <td>4.242656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <td>2.246606</td>\n",
       "      <td>9.490197</td>\n",
       "      <td>2.711820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <td>2.525159</td>\n",
       "      <td>7.615379</td>\n",
       "      <td>3.264081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi_se</th>\n",
       "      <td>2.690311</td>\n",
       "      <td>3.280663</td>\n",
       "      <td>3.942102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi_sw</th>\n",
       "      <td>4.025909</td>\n",
       "      <td>3.234273</td>\n",
       "      <td>6.650551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <td>6.139555</td>\n",
       "      <td>3.111873</td>\n",
       "      <td>9.211951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <td>3.016941</td>\n",
       "      <td>3.041026</td>\n",
       "      <td>5.982186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
       "      <td>1.618934</td>\n",
       "      <td>2.597984</td>\n",
       "      <td>1.962594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1.139403</td>\n",
       "      <td>2.130203</td>\n",
       "      <td>1.293049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi_nw</th>\n",
       "      <td>2.845429</td>\n",
       "      <td>1.950984</td>\n",
       "      <td>4.045501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_precip_mm</th>\n",
       "      <td>1.278384</td>\n",
       "      <td>1.893128</td>\n",
       "      <td>1.648298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <td>1.495283</td>\n",
       "      <td>1.855394</td>\n",
       "      <td>1.737527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <td>5.927034</td>\n",
       "      <td>1.819038</td>\n",
       "      <td>7.742019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi_ne</th>\n",
       "      <td>4.748647</td>\n",
       "      <td>1.676724</td>\n",
       "      <td>6.738472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekofyear</th>\n",
       "      <td>1.266012</td>\n",
       "      <td>1.600839</td>\n",
       "      <td>1.513544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        vif_iq     vif_sj  vif_total\n",
       "station_avg_temp_c                    2.903773  15.205912   4.242656\n",
       "station_min_temp_c                    2.246606   9.490197   2.711820\n",
       "station_max_temp_c                    2.525159   7.615379   3.264081\n",
       "ndvi_se                               2.690311   3.280663   3.942102\n",
       "ndvi_sw                               4.025909   3.234273   6.650551\n",
       "reanalysis_relative_humidity_percent  6.139555   3.111873   9.211951\n",
       "station_diur_temp_rng_c               3.016941   3.041026   5.982186\n",
       "reanalysis_precip_amt_kg_per_m2       1.618934   2.597984   1.962594\n",
       "year                                  1.139403   2.130203   1.293049\n",
       "ndvi_nw                               2.845429   1.950984   4.045501\n",
       "station_precip_mm                     1.278384   1.893128   1.648298\n",
       "precipitation_amt_mm                  1.495283   1.855394   1.737527\n",
       "reanalysis_tdtr_k                     5.927034   1.819038   7.742019\n",
       "ndvi_ne                               4.748647   1.676724   6.738472\n",
       "weekofyear                            1.266012   1.600839   1.513544"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_vif_post = df_train_clean.groupby(by=CITYGROUP_FEAT).apply(lambda group: top_vif(data=group), include_groups=False)\n",
    "temp_vif_post =  temp_vif_post.loc[\"iq\"].join(temp_vif_post.loc[\"sj\"], lsuffix=\"_iq\", rsuffix=\"_sj\", how=\"inner\")\n",
    "temp_vif_post[\"vif_total\"] = top_vif(data=df_train_clean).values\n",
    "temp_vif_post.sort_values(by=\"vif_sj\", ascending=False, na_position=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f57b62b4-5259-4692-a50b-abca38603cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City-stratified correlations exceeding 0.8:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "city                                                          \n",
       "iq    ndvi_ne             ndvi_sw                                 0.840730\n",
       "      reanalysis_tdtr_k   reanalysis_relative_humidity_percent   -0.900588\n",
       "sj    station_min_temp_c  station_avg_temp_c                      0.898016\n",
       "      station_max_temp_c  station_avg_temp_c                      0.864780\n",
       "      ndvi_sw             ndvi_se                                 0.819673\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_threshold=0.8\n",
    "print(f\"City-stratified correlations exceeding {corr_threshold}:\")\n",
    "df_train_clean.groupby(\n",
    "    by=CITYGROUP_FEAT).apply(\n",
    "        lambda group: top_correlations(\n",
    "            data=group, \n",
    "            corr_threshold=corr_threshold\n",
    "        ), include_groups=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77aaff-e54d-4620-88a6-07e5826769db",
   "metadata": {},
   "source": [
    "**Conclusion**:\n",
    "- Overall `vif_total` Variance Inflation Factor cobined for both cities is below 10:\n",
    "  - Among highest VIF scoring overall remains `reanalysis_relative_humidity_percent`, but it is important as there are no alternative station humiidity data and humidity is important for dengue detection domain. \n",
    "- `San Juan` still suffers from higher Multicolinearity that reflects geographical characteristic (more stable climate):\n",
    "    - Top VIF scores for `San Juan` reach 15.2 and are in crucial station  temperature measurements. `station_avg_temp_c` could be potentially removed, but risks hiding important signals in `Iquitos`.\n",
    "    - Keep `station_avg_temp_c` and observe model results:\n",
    "        - VIF score of ~ 15 should be well handled by `LightGBM`\n",
    "        - If `LTSM` `San Juan` -> `Iquitos` transfer learn underperforms, attempt addinf `station_avg_temp_c` to `config.yaml` feature removal list. \n",
    "- VIF factors for `Iquitos` are all acceptable in range below ~6.1.\n",
    "- Remaining high correlation pairs are differenft for both cities confirming that closeness of these features are city specific and thus may encompass important signals for models. So they are kept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052d6b2-ff0f-49f5-bfdd-a167cb84a18f",
   "metadata": {},
   "source": [
    "### RobustScaler (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff980866-f6fd-4447-b13c-5bdf835c9b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa957889-241d-46c9-ad08-75eb1e3d3637",
   "metadata": {},
   "source": [
    "## Target processing\n",
    "- [ ] Process zero/low value target value streaks\n",
    "- [ ] RobustScaler (Targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0c5ab-7e57-41ee-b9d0-61df72b9ba30",
   "metadata": {},
   "source": [
    "### Process zero/low value target value streaks\n",
    "- [ ] Predict log1p(total_cases) to reduce zero target influence (log transform targets)\n",
    "- [ ] (Optional) LSTM specific - if LSTM results are sub-optimal, experiment with downweighting affected period data (ie 0.3 or more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9897a8-e9b8-4f76-90e6-0152c8b7bce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68e7ec52-20e1-474b-9fd1-e5b245421573",
   "metadata": {},
   "source": [
    "# TODO: adjust **Conclusion**:\n",
    "- Target outliers are "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c98e5-e188-4d48-8084-d4d2d6ce1fbe",
   "metadata": {},
   "source": [
    "### RobustScaler (targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34972d66-6086-4e3f-8558-75c83efbca12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c9422f-ae90-49f6-8a9b-38a327c38b7d",
   "metadata": {},
   "source": [
    "# TODO Research before applying:\n",
    "- **Final Preprocessing tactics for outliers:**\n",
    "    - Target (\"total_cases\")\n",
    "        - If tree models used (eg LightGBM) - no issue, trees are not sensitive to outliers:\n",
    "            - [ ] use huber loss for extra safety when handling tails\n",
    "            - [ ] RobustScaler may be redunndant for tree models, but if it simplifies pipeline - no harm.\n",
    "        - RNNs (eg LSTM) are outlier sensitive (gradient instability, hidden state patterns loose importance at peaks, scaling):\n",
    "            - [ ] Log transform\n",
    "            - [ ] Scale (RobustScaler  with IQR is more outlier resistant)\n",
    "            - [ ] apply huber loss\n",
    "    - Features:\n",
    "        - [ ] RobustScaler for RNN\n",
    "        - [ ] RobustScaler may be redunndant for tree models, but if it simplifies pipeline - no harm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd9c66-621d-4d47-88ad-8e74b4283a1f",
   "metadata": {},
   "source": [
    "separate tactics for baseline tree modela and RNN.\n",
    "- Tree (eg LighGBM):\n",
    "    - drop redundant and higgly correlated reanalysis features, replace with engineered features that provide temporal info\n",
    "    - single vector input:\n",
    "        - weather/vegetation snapshot for t-1 week:\n",
    "            - keep these features (poss few more):\n",
    "                1. city\n",
    "                2. sin/cos_weekofyear (cyclical),\n",
    "                3. station_avg_temp_c,\n",
    "                4. station_precip_mm,\n",
    "                5. station_min_temp_c/station_max_temp_c,\n",
    "                6. ndvi_ne/ndvi_sw,\n",
    "                7. reanalysis_relative_humidity_percent\n",
    "        - multiple lagged/aggregated case metrics.\n",
    "            - see next cell\n",
    "            - add:\n",
    "                -  4w rolling means\n",
    "                -  4w rollong max\n",
    "                -  w1-w4 lags (4 features)\n",
    "        - multiple lagged/aggregated weather features:\n",
    "            - 4w averages for temp, rain, humidity\n",
    "        - limit to 25 dimensions (preferably 20)\n",
    "- RNN (eg LSTM)\n",
    "    - keep most original features, drop extremes of 2-3 highly collinear reanalysis, minimal engineering \n",
    "    - windowed input with:\n",
    "        -  4-8 time steps (if single step/week forecast)\n",
    "        -  10-20 features per step\n",
    "        -  include city embedding (research if truly needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bafab69-0ded-48a9-a91f-535f7eedefce",
   "metadata": {},
   "source": [
    "Conclusions from EDA notebook (~ line 33)\n",
    "- Tree models may handle interrupted seasonality better, but:\n",
    "    - with adittional feature engineering:\n",
    "      - seasonal cyclical sin/cos features (weekly on annual basis)\n",
    "      - weekly case autocorrelation/shift() (must) or annual shift features (indicate time momentum for tree model):\n",
    "          - trees can handle resulting NaNs\n",
    "      - weekly per city differencing to hughlight spikes and sudue seasonality - stationary (constant statistical properties over time) benefit trees.\n",
    "      - Optional: annual diff feature for outbreak signals per city\n",
    "-  RNNs (eg LSTM) will struggle with outbreak spikes as works best with smooth seasonal patterns:\n",
    "    - still may benefit from  cyclical sin/cos features\n",
    "    - precip_avg_4w\n",
    "    - Rolling_mean_cases_4w (handle NaNs, eg impute with bfill() + ffill() combo)\n",
    "    - lag1_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aff70d-d1d5-4797-bdbe-738923b81346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba: py311_data_prep",
   "language": "python",
   "name": "py311_data_prep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
